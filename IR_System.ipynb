{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Music Retrieval - A Boolean Retrieval Approach\n",
    "\n",
    "In this notebook a solution for the retrieval of songs based on boolean queries is presented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/akasnipe/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/akasnipe/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Load libraries\n",
    "## Anaconda 3 is used with Python 3.11.4\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "import string\n",
    "from functools import total_ordering\n",
    "import re\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset contains lyrics of songs in the English language, from 1950 to 2019."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist_name</th>\n",
       "      <th>track_name</th>\n",
       "      <th>release_date</th>\n",
       "      <th>genre</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>len</th>\n",
       "      <th>dating</th>\n",
       "      <th>violence</th>\n",
       "      <th>world/life</th>\n",
       "      <th>night/time</th>\n",
       "      <th>shake the audience</th>\n",
       "      <th>family/gospel</th>\n",
       "      <th>romantic</th>\n",
       "      <th>communication</th>\n",
       "      <th>obscene</th>\n",
       "      <th>music</th>\n",
       "      <th>movement/places</th>\n",
       "      <th>light/visual perceptions</th>\n",
       "      <th>family/spiritual</th>\n",
       "      <th>like/girls</th>\n",
       "      <th>sadness</th>\n",
       "      <th>feelings</th>\n",
       "      <th>danceability</th>\n",
       "      <th>loudness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>valence</th>\n",
       "      <th>energy</th>\n",
       "      <th>topic</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mukesh</td>\n",
       "      <td>mohabbat bhi jhoothi</td>\n",
       "      <td>1950</td>\n",
       "      <td>pop</td>\n",
       "      <td>hold time feel break feel untrue convince spea...</td>\n",
       "      <td>95</td>\n",
       "      <td>0.000598</td>\n",
       "      <td>0.063746</td>\n",
       "      <td>0.000598</td>\n",
       "      <td>0.000598</td>\n",
       "      <td>0.000598</td>\n",
       "      <td>0.048857</td>\n",
       "      <td>0.017104</td>\n",
       "      <td>0.263751</td>\n",
       "      <td>0.000598</td>\n",
       "      <td>0.039288</td>\n",
       "      <td>0.000598</td>\n",
       "      <td>0.000598</td>\n",
       "      <td>0.000598</td>\n",
       "      <td>0.000598</td>\n",
       "      <td>0.380299</td>\n",
       "      <td>0.117175</td>\n",
       "      <td>0.357739</td>\n",
       "      <td>0.454119</td>\n",
       "      <td>0.997992</td>\n",
       "      <td>0.901822</td>\n",
       "      <td>0.339448</td>\n",
       "      <td>0.137110</td>\n",
       "      <td>sadness</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>frankie laine</td>\n",
       "      <td>i believe</td>\n",
       "      <td>1950</td>\n",
       "      <td>pop</td>\n",
       "      <td>believe drop rain fall grow believe darkest ni...</td>\n",
       "      <td>51</td>\n",
       "      <td>0.035537</td>\n",
       "      <td>0.096777</td>\n",
       "      <td>0.443435</td>\n",
       "      <td>0.001284</td>\n",
       "      <td>0.001284</td>\n",
       "      <td>0.027007</td>\n",
       "      <td>0.001284</td>\n",
       "      <td>0.001284</td>\n",
       "      <td>0.001284</td>\n",
       "      <td>0.118034</td>\n",
       "      <td>0.001284</td>\n",
       "      <td>0.212681</td>\n",
       "      <td>0.051124</td>\n",
       "      <td>0.001284</td>\n",
       "      <td>0.001284</td>\n",
       "      <td>0.001284</td>\n",
       "      <td>0.331745</td>\n",
       "      <td>0.647540</td>\n",
       "      <td>0.954819</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.325021</td>\n",
       "      <td>0.263240</td>\n",
       "      <td>world/life</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>johnnie ray</td>\n",
       "      <td>cry</td>\n",
       "      <td>1950</td>\n",
       "      <td>pop</td>\n",
       "      <td>sweetheart send letter goodbye secret feel bet...</td>\n",
       "      <td>24</td>\n",
       "      <td>0.002770</td>\n",
       "      <td>0.002770</td>\n",
       "      <td>0.002770</td>\n",
       "      <td>0.002770</td>\n",
       "      <td>0.002770</td>\n",
       "      <td>0.002770</td>\n",
       "      <td>0.158564</td>\n",
       "      <td>0.250668</td>\n",
       "      <td>0.002770</td>\n",
       "      <td>0.323794</td>\n",
       "      <td>0.002770</td>\n",
       "      <td>0.002770</td>\n",
       "      <td>0.002770</td>\n",
       "      <td>0.002770</td>\n",
       "      <td>0.002770</td>\n",
       "      <td>0.225422</td>\n",
       "      <td>0.456298</td>\n",
       "      <td>0.585288</td>\n",
       "      <td>0.840361</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.351814</td>\n",
       "      <td>0.139112</td>\n",
       "      <td>music</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pérez prado</td>\n",
       "      <td>patricia</td>\n",
       "      <td>1950</td>\n",
       "      <td>pop</td>\n",
       "      <td>kiss lips want stroll charm mambo chacha merin...</td>\n",
       "      <td>54</td>\n",
       "      <td>0.048249</td>\n",
       "      <td>0.001548</td>\n",
       "      <td>0.001548</td>\n",
       "      <td>0.001548</td>\n",
       "      <td>0.021500</td>\n",
       "      <td>0.001548</td>\n",
       "      <td>0.411536</td>\n",
       "      <td>0.001548</td>\n",
       "      <td>0.001548</td>\n",
       "      <td>0.001548</td>\n",
       "      <td>0.129250</td>\n",
       "      <td>0.001548</td>\n",
       "      <td>0.001548</td>\n",
       "      <td>0.081132</td>\n",
       "      <td>0.225889</td>\n",
       "      <td>0.001548</td>\n",
       "      <td>0.686992</td>\n",
       "      <td>0.744404</td>\n",
       "      <td>0.083935</td>\n",
       "      <td>0.199393</td>\n",
       "      <td>0.775350</td>\n",
       "      <td>0.743736</td>\n",
       "      <td>romantic</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>giorgos papadopoulos</td>\n",
       "      <td>apopse eida oneiro</td>\n",
       "      <td>1950</td>\n",
       "      <td>pop</td>\n",
       "      <td>till darling till matter know till dream live ...</td>\n",
       "      <td>48</td>\n",
       "      <td>0.001350</td>\n",
       "      <td>0.001350</td>\n",
       "      <td>0.417772</td>\n",
       "      <td>0.001350</td>\n",
       "      <td>0.001350</td>\n",
       "      <td>0.001350</td>\n",
       "      <td>0.463430</td>\n",
       "      <td>0.001350</td>\n",
       "      <td>0.001350</td>\n",
       "      <td>0.001350</td>\n",
       "      <td>0.001350</td>\n",
       "      <td>0.001350</td>\n",
       "      <td>0.029755</td>\n",
       "      <td>0.001350</td>\n",
       "      <td>0.068800</td>\n",
       "      <td>0.001350</td>\n",
       "      <td>0.291671</td>\n",
       "      <td>0.646489</td>\n",
       "      <td>0.975904</td>\n",
       "      <td>0.000246</td>\n",
       "      <td>0.597073</td>\n",
       "      <td>0.394375</td>\n",
       "      <td>romantic</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            artist_name            track_name  release_date genre  \\\n",
       "0                mukesh  mohabbat bhi jhoothi          1950   pop   \n",
       "1         frankie laine             i believe          1950   pop   \n",
       "2           johnnie ray                   cry          1950   pop   \n",
       "3           pérez prado              patricia          1950   pop   \n",
       "4  giorgos papadopoulos    apopse eida oneiro          1950   pop   \n",
       "\n",
       "                                              lyrics  len    dating  violence  \\\n",
       "0  hold time feel break feel untrue convince spea...   95  0.000598  0.063746   \n",
       "1  believe drop rain fall grow believe darkest ni...   51  0.035537  0.096777   \n",
       "2  sweetheart send letter goodbye secret feel bet...   24  0.002770  0.002770   \n",
       "3  kiss lips want stroll charm mambo chacha merin...   54  0.048249  0.001548   \n",
       "4  till darling till matter know till dream live ...   48  0.001350  0.001350   \n",
       "\n",
       "   world/life  night/time  shake the audience  family/gospel  romantic  \\\n",
       "0    0.000598    0.000598            0.000598       0.048857  0.017104   \n",
       "1    0.443435    0.001284            0.001284       0.027007  0.001284   \n",
       "2    0.002770    0.002770            0.002770       0.002770  0.158564   \n",
       "3    0.001548    0.001548            0.021500       0.001548  0.411536   \n",
       "4    0.417772    0.001350            0.001350       0.001350  0.463430   \n",
       "\n",
       "   communication   obscene     music  movement/places  \\\n",
       "0       0.263751  0.000598  0.039288         0.000598   \n",
       "1       0.001284  0.001284  0.118034         0.001284   \n",
       "2       0.250668  0.002770  0.323794         0.002770   \n",
       "3       0.001548  0.001548  0.001548         0.129250   \n",
       "4       0.001350  0.001350  0.001350         0.001350   \n",
       "\n",
       "   light/visual perceptions  family/spiritual  like/girls   sadness  feelings  \\\n",
       "0                  0.000598          0.000598    0.000598  0.380299  0.117175   \n",
       "1                  0.212681          0.051124    0.001284  0.001284  0.001284   \n",
       "2                  0.002770          0.002770    0.002770  0.002770  0.225422   \n",
       "3                  0.001548          0.001548    0.081132  0.225889  0.001548   \n",
       "4                  0.001350          0.029755    0.001350  0.068800  0.001350   \n",
       "\n",
       "   danceability  loudness  acousticness  instrumentalness   valence    energy  \\\n",
       "0      0.357739  0.454119      0.997992          0.901822  0.339448  0.137110   \n",
       "1      0.331745  0.647540      0.954819          0.000002  0.325021  0.263240   \n",
       "2      0.456298  0.585288      0.840361          0.000000  0.351814  0.139112   \n",
       "3      0.686992  0.744404      0.083935          0.199393  0.775350  0.743736   \n",
       "4      0.291671  0.646489      0.975904          0.000246  0.597073  0.394375   \n",
       "\n",
       "        topic  age  \n",
       "0     sadness  1.0  \n",
       "1  world/life  1.0  \n",
       "2       music  1.0  \n",
       "3    romantic  1.0  \n",
       "4    romantic  1.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/data.csv', sep=\",\", index_col=0).reset_index(drop=True)\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there are many columns with numerical values, that should be used for Sentiment Analysis, only `artist_name`, `track_name`, `genre`, `lyrics` and `topic` will be used for the retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist_name</th>\n",
       "      <th>track_name</th>\n",
       "      <th>genre</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mukesh</td>\n",
       "      <td>mohabbat bhi jhoothi</td>\n",
       "      <td>pop</td>\n",
       "      <td>hold time feel break feel untrue convince spea...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>frankie laine</td>\n",
       "      <td>i believe</td>\n",
       "      <td>pop</td>\n",
       "      <td>believe drop rain fall grow believe darkest ni...</td>\n",
       "      <td>world/life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>johnnie ray</td>\n",
       "      <td>cry</td>\n",
       "      <td>pop</td>\n",
       "      <td>sweetheart send letter goodbye secret feel bet...</td>\n",
       "      <td>music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pérez prado</td>\n",
       "      <td>patricia</td>\n",
       "      <td>pop</td>\n",
       "      <td>kiss lips want stroll charm mambo chacha merin...</td>\n",
       "      <td>romantic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>giorgos papadopoulos</td>\n",
       "      <td>apopse eida oneiro</td>\n",
       "      <td>pop</td>\n",
       "      <td>till darling till matter know till dream live ...</td>\n",
       "      <td>romantic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            artist_name            track_name genre  \\\n",
       "0                mukesh  mohabbat bhi jhoothi   pop   \n",
       "1         frankie laine             i believe   pop   \n",
       "2           johnnie ray                   cry   pop   \n",
       "3           pérez prado              patricia   pop   \n",
       "4  giorgos papadopoulos    apopse eida oneiro   pop   \n",
       "\n",
       "                                              lyrics       topic  \n",
       "0  hold time feel break feel untrue convince spea...     sadness  \n",
       "1  believe drop rain fall grow believe darkest ni...  world/life  \n",
       "2  sweetheart send letter goodbye secret feel bet...       music  \n",
       "3  kiss lips want stroll charm mambo chacha merin...    romantic  \n",
       "4  till darling till matter know till dream live ...    romantic  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data[['artist_name', 'track_name','genre', 'lyrics', 'topic']]\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IR System\n",
    "\n",
    "The system will be composed of the following classes:\n",
    "* Posting: The class to implement the Posting objects,\n",
    "* Posting List: The class to implement the Posting List objects,\n",
    "* Term: The class to implement the Term objects,\n",
    "* Inverted Index: The class to implement the Inverted Index objects for Boolean Retrieval,\n",
    "* Song: The class to implement the Song objects,\n",
    "* IR System: The \"main\" class that puts everything together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Posting class\n",
    "\n",
    "@total_ordering\n",
    "class Posting:\n",
    "    \n",
    "    # Initializer, takes a document ID as an argument.\n",
    "    def __init__(self, docID):\n",
    "        self._docID = docID\n",
    "    \n",
    "    # Retrieve a document's contents from a corpus using the document ID.\n",
    "    def get_from_corpus(self, corpus):\n",
    "        return corpus[self._docID]\n",
    "    \n",
    "    # Check equality with another Posting, based on document ID.\n",
    "    def __eq__(self, other):\n",
    "        return self._docID == other._docID\n",
    "    \n",
    "    # Check if this Posting has document ID greater than another Posting.\n",
    "    def __gt__(self, other):\n",
    "        return self._docID > other._docID\n",
    "    \n",
    "    # Provide the string representation of the Posting.\n",
    "    def __repr__(self):\n",
    "        return str(self._docID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Posting List class\n",
    "\n",
    "class PostingList:\n",
    "\n",
    "    # Initializer, initializes an empty list of postings.\n",
    "    def __init__(self):\n",
    "        self._postings = []\n",
    "    \n",
    "    # Create a PostingList instance with a single Posting from a document ID.\n",
    "    @classmethod\n",
    "    def from_docID(cls, docID):\n",
    "        posting_list = cls()\n",
    "        posting_list._postings = [(Posting(docID))]\n",
    "        return posting_list\n",
    "    \n",
    "    # Create a PostingList instance from an existing list of Postings.\n",
    "    @classmethod\n",
    "    def from_posting_list(cls, postingList):\n",
    "        plist = cls()\n",
    "        plist._postings = postingList\n",
    "        return plist\n",
    "\n",
    "    # Merge another PostingList into this one, avoiding duplicates.\n",
    "    def merge(self, other):\n",
    "        i = 0  # Index for the other PostingList.\n",
    "        last = self._postings[-1]  # The last Posting in the current list.\n",
    "\n",
    "        while (i < len(other._postings) and last == other._postings[i]):\n",
    "            i += 1  # Increment the index if a duplicate is found.\n",
    "        self._postings += other._postings[i:]  # Append the non-duplicate postings from the other list.\n",
    "    \n",
    "    # Compute the intersection of this PostingList with another.\n",
    "    def intersection(self, other):\n",
    "        intersection = []  # Start with an empty list for the intersection.\n",
    "        i = 0  # Index for this PostingList.\n",
    "        j = 0  # Index for the other PostingList.\n",
    "\n",
    "        while (i < len(self._postings) and j < len(other._postings)): # Loop until one of the lists is exhausted.\n",
    "            if (self._postings[i] == other._postings[j]):\n",
    "                intersection.append(self._postings[i]) # If both postings are equal, add to the intersection.\n",
    "                i += 1 # Increment both indexes.\n",
    "                j += 1\n",
    "            # If postings are different, increment the index for the list with the smallest value.\n",
    "            elif (self._postings[i] < other._postings[j]):\n",
    "                i += 1\n",
    "            else:\n",
    "                j += 1\n",
    "        return PostingList.from_posting_list(intersection)  # Return a new PostingList of the intersection.\n",
    "\n",
    "    # Compute the union of this PostingList with another.\n",
    "    def union(self, other):\n",
    "        union = []  # Start with an empty list for the union.\n",
    "        i = 0  # Index for this PostingList.\n",
    "        j = 0  # Index for the other PostingList.\n",
    "        while (i < len(self._postings) and j < len(other._postings)): # Loop until one of the lists is exhausted.\n",
    "            if (self._postings[i] == other._postings[j]):\n",
    "                union.append(self._postings[i]) # If both postings are equal, add one to the union.\n",
    "                i += 1 # Increment both indexes.\n",
    "                j += 1\n",
    "            # If postings are different, add the posting with the smallest value to the union and increment its index.\n",
    "            elif (self._postings[i] < other._postings[j]):\n",
    "                union.append(self._postings[i])\n",
    "                i += 1\n",
    "            else:\n",
    "                union.append(other._postings[j])\n",
    "                j += 1\n",
    "        # Add any remaining postings from both lists to the union.\n",
    "        for k in range(i, len(self._postings)):\n",
    "            union.append(self._postings[k])\n",
    "        for k in range(j, len(other._postings)):\n",
    "            union.append(other._postings[k])\n",
    "        return PostingList.from_posting_list(union)  # Return a new PostingList of the union.\n",
    "    \n",
    "    # Retrieve the contents of each Posting from a corpus.\n",
    "    def get_from_corpus(self, corpus):\n",
    "        return list(map(lambda x: x.get_from_corpus(corpus), self._postings))\n",
    "    \n",
    "    # Provide the string representation of the PostingList.\n",
    "    def __repr__(self):\n",
    "        return \", \".join(map(str, self._postings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Term class\n",
    "\n",
    "# Exception class for handling merge operation errors.\n",
    "class ImpossibleMergeError(Exception):\n",
    "    pass\n",
    "\n",
    "# A class that represents a term in a document, along with its posting list.\n",
    "@total_ordering\n",
    "class Term:\n",
    "\n",
    "    # Initializer, takes a term and a document ID as arguments.\n",
    "    def __init__(self, term, docID):\n",
    "        self.term = term\n",
    "        # Initialize posting_list for the term with a PostingList created from the given document ID.\n",
    "        self.posting_list = PostingList.from_docID(docID)\n",
    "\n",
    "    # Merge another Term's posting list into this one if they have the same term.\n",
    "    def merge(self, other):\n",
    "        if (self.term == other.term):\n",
    "            self.posting_list.merge(other.posting_list)\n",
    "        else:\n",
    "            raise ImpossibleMergeError\n",
    "    \n",
    "    # Check equality with another Term.\n",
    "    def __eq__(self, other):\n",
    "        return self.term == other.term\n",
    "    \n",
    "    # Determine if this Term is greater than another.\n",
    "    def __gt__(self, other):\n",
    "        return self.term > other.term\n",
    "    \n",
    "    # Provide the string representation of the Term.\n",
    "    def __repr__(self):\n",
    "        return self.term + \": \" + repr(self.posting_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before defining the Inverted Index class, let's define functions to perform normalization, stemming and lemmatization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop Word removal, Normalization and Stemming/Lemmatization\n",
    "\n",
    "def remove_stop_words(text):\n",
    "     \n",
    "    # Start from a list containing the tokens in \"text\"\n",
    "    text_list = text.split()\n",
    "\n",
    "    # Filter out stop words\n",
    "    text_list = [word for word in text_list if word not in set(nltk.corpus.stopwords.words('english'))]\n",
    "\n",
    "    # Join the remaining words into a single string\n",
    "    result = \" \".join(text_list)\n",
    "\n",
    "    return result\n",
    "\n",
    "def normalize(text):\n",
    "\n",
    "    # Make a translation table that maps all punctuation characters to None\n",
    "    translator = str.maketrans(\"\", \"\", string.punctuation)\n",
    "\n",
    "    # Apply the translation table to the input string\n",
    "    result = text.translate(translator)\n",
    "\n",
    "    # Converts the text to lowercase.\n",
    "    result = result.lower()\n",
    "\n",
    "    return result\n",
    "\n",
    "def stem(text, type='porter'):\n",
    "        \n",
    "    # Start from a list containing the tokens in \"text\"\n",
    "    stemmed_text = text.split()\n",
    "\n",
    "    # Create a stemmer object\n",
    "    if type == 'porter':\n",
    "        stemmer = nltk.stem.porter.PorterStemmer()\n",
    "    elif type == 'snowball':\n",
    "        stemmer = nltk.stem.snowball.SnowballStemmer(\"english\")\n",
    "    else:\n",
    "        raise ValueError('Stemmer type not supported')\n",
    "\n",
    "    # Loop through each word in the text and retrieve the stem\n",
    "    for i in range(len(stemmed_text)):\n",
    "        stemmed_text[i] = stemmer.stem(stemmed_text[i])\n",
    "\n",
    "    # Join the stemmed words into a single string\n",
    "    result = \" \".join(stemmed_text)\n",
    "\n",
    "    return result\n",
    "\n",
    "def lemmatize(text):\n",
    "     # Start from a list containing the tokens in \"text\"\n",
    "        lemmatized_text = text.split()\n",
    "    \n",
    "        # Create a lemmatizer object\n",
    "        lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "    \n",
    "        # Loop through each word in the text and retrieve the lemma\n",
    "        for i in range(len(lemmatized_text)):\n",
    "            lemmatized_text[i] = lemmatizer.lemmatize(lemmatized_text[i])\n",
    "    \n",
    "        # Join the lemmatized words into a single string\n",
    "        result = \" \".join(lemmatized_text)\n",
    "    \n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inverted Index class\n",
    "\n",
    "class InvertedIndex:\n",
    "    \n",
    "    # Initialize the inverted index with an empty dictionary.\n",
    "    def __init__(self):\n",
    "        self._dictionary = []\n",
    "        \n",
    "    # Create an inverted index from a corpus of documents\n",
    "    ## Argument word_reduction_type enables to choose between stemming and lemmatization\n",
    "    ## Argument stop_words enables to maintain stop words (stop_words=True) or remove them (stop_words=False)\n",
    "    @classmethod\n",
    "    def from_corpus(cls, corpus, word_reduction_type = 'stemming_porter', stop_words = True):\n",
    "        intermediate_dict = {}  # Intermediate dictionary to store the terms and their postings.\n",
    "        for docID, song in enumerate(corpus):\n",
    "            # Remove stop words, normalize and stem/lemmatize\n",
    "            document = song.lyrics\n",
    "            if not stop_words:\n",
    "                document = remove_stop_words(document)\n",
    "            document = normalize(document)\n",
    "            if word_reduction_type == 'stemming_porter':\n",
    "                document = stem(document, type = 'porter')\n",
    "            elif word_reduction_type == 'stemming_snowball':\n",
    "                document = stem(document, type = 'snowball')\n",
    "            elif word_reduction_type == 'lemmatization':\n",
    "                document = lemmatize(document)\n",
    "            tokens = list(document.split()) # Tokenize the document into individual words.\n",
    "            biwords = [tokens[i]+' '+tokens[i+1] for i in range(len(tokens)-1)] # Get all biwords in the document.\n",
    "            for token in tokens:\n",
    "                term = Term(token, docID) # Create a new term with the token and the current document ID.\n",
    "                try: # Try to merge the term with existing one in the intermediate dictionary.\n",
    "                    intermediate_dict[token].merge(term)\n",
    "                except KeyError: # If the term is not already in the dictionary, add it.\n",
    "                    intermediate_dict[token] = term\n",
    "            for biword in biwords:\n",
    "                term = Term(biword, docID) # Create a new term with the biword and the current document ID.\n",
    "                try: # Try to merge the term with existing one in the intermediate dictionary.\n",
    "                    intermediate_dict[biword].merge(term)\n",
    "                except KeyError: # If the term is not already in the dictionary, add it.\n",
    "                    intermediate_dict[biword] = term\n",
    "        idx = cls() # Create a new InvertedIndex instance.\n",
    "        idx._dictionary = sorted(intermediate_dict.values(), key=lambda term: term.term) # Sort the terms in the intermediate dictionary and store them in the index's dictionary.\n",
    "        return idx\n",
    "    \n",
    "    # Retrieve the posting list for a given term.\n",
    "    def __getitem__(self, key):\n",
    "        for term in self._dictionary:\n",
    "            if term.term == key: # If the term matches the key, return its posting list.\n",
    "                return term.posting_list\n",
    "        raise KeyError(\"No song matches the given query.\") # If the term is not in the dictionary, raise a KeyError.\n",
    "    \n",
    "    # Provide a string representation of the inverted index.\n",
    "    def __repr__(self):\n",
    "        return \"A dictionary with \" + str(len(self._dictionary)) + \" terms\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Song class\n",
    "\n",
    "# Class to hold the title, author, genre, topic and lyrics of a song\n",
    "class Song:\n",
    "    \n",
    "    # Initializer, initializes the title, author, genre, topic and lyrics attributes.\n",
    "    def __init__(self, title, author, lyrics):\n",
    "        self.title = title\n",
    "        self.author = author\n",
    "        self.lyrics = lyrics\n",
    "        \n",
    "    # Provide the string representation of the Song object.\n",
    "    def __repr__(self):\n",
    "        return \"Title: \" + self.title + \",\\nAuthor: \" + self.author + \"\\n\\n\"\n",
    "    \n",
    "# Get song author, title and lyrics from data\n",
    "def get_songs_data(path):\n",
    "    data = pd.read_csv(path, sep=\",\")\n",
    "    # Remove newline characters from song lyrics\n",
    "    data['text'] = data['text'].replace('\\r\\n',' ', regex=True)\n",
    "    corpus = []\n",
    "    for index, item in data.iterrows():\n",
    "        song = Song(title = item['song'],\n",
    "                    author = item['artist'],\n",
    "                    lyrics = item['text'])\n",
    "        # Add the Song object to the corpus.\n",
    "        corpus.append(song)\n",
    "    # Return the populated list of MovieDescription objects.\n",
    "    return corpus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Information Retrieval (IR) system class\n",
    "\n",
    "class IRsystem:\n",
    "\n",
    "    # Initialize the IR system with a corpus and the inverted index.   \n",
    "    def __init__(self, corpus, index):\n",
    "        self._corpus = corpus\n",
    "        self._index = index\n",
    "    \n",
    "    # Create an IR system instance from a given corpus.\n",
    "    @classmethod\n",
    "    def from_corpus(cls, corpus, word_reduction_type = 'stemming_porter', stop_words=True):\n",
    "        index = InvertedIndex.from_corpus(corpus, word_reduction_type, stop_words)\n",
    "        return cls(corpus, index)\n",
    "    \n",
    "    # Return the posting list of a given posting\n",
    "    def get_posting_list(self, posting):\n",
    "        # Retrieve the posting list from the index.\n",
    "        posting_list = self._index[posting]\n",
    "        # Return the list of documents.\n",
    "        return posting_list.get_from_corpus(self._corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to execute a text query against an IR system.\n",
    "\n",
    "def query(ir, query, word_reduction_type = 'stemming_porter'):\n",
    "    answer = set()\n",
    "    # Split the text query into individual words/biwords.\n",
    "    words = re.split('(AND|OR|NOT)', query)\n",
    "    for i in range(len(words)):\n",
    "        words[i] = words[i].strip()\n",
    "    # Check if the first or the last word is a boolean operator and return an error.\n",
    "    if words[0] in [\"AND\", \"OR\", \"NOT\"] or words[len(words)-1] in [\"AND\", \"OR\", \"NOT\"]:\n",
    "        raise KeyError(\"The first and the last word of the query cannot be a boolean operator.\")\n",
    "    # Normalize and stem/lemmatize the query words/biwords but not the boolean operators.\n",
    "    for i in range(len(words)):\n",
    "        if words[i] not in [\"AND\", \"OR\", \"NOT\"]:\n",
    "            if word_reduction_type == 'stemming_porter':                   \n",
    "                words[i] = stem(normalize(words[i]), type = 'porter')\n",
    "            elif word_reduction_type == 'stemming_snowball':\n",
    "                words[i] = stem(normalize(words[i]), type = 'snowball')\n",
    "            elif word_reduction_type == 'lemmatization':\n",
    "                words[i] = lemmatize(normalize(words[i]))\n",
    "    # Retrieve the posting list for the first word/biword from the index.\n",
    "    result = ir.get_posting_list(words[0])\n",
    "    for song in result:\n",
    "        answer.add(song)\n",
    "    # Loop through the remaining words in the query.\n",
    "    for i in range(1, len(words), 2):\n",
    "        # Retrieve the posting lists for the next word from the index.\n",
    "        result = ir.get_posting_list(words[i+1])\n",
    "        # Case AND: Intersect the current answer with the new posting lists.\n",
    "        if words[i] == \"AND\":\n",
    "            answer = answer.intersection(result)\n",
    "        # Case OR: Union the current answer with the new posting lists.\n",
    "        elif words[i] == \"OR\":\n",
    "            answer = answer.union(result)\n",
    "        # Case NOT: Subtract the new posting lists from the current answer.\n",
    "        elif words[i] == \"NOT\":\n",
    "            answer = answer.difference(result)\n",
    "    # Print out each song that matches the query.\n",
    "    ## If no song matches the query, print out a message.\n",
    "    if len(answer) == 0:\n",
    "        raise KeyError(\"No song matches the given query.\")\n",
    "    for song in answer:\n",
    "        print(song)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test the Boolean Retrieval System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = get_songs_data(\"data/spotify_millsongdata.csv\")\n",
    "\n",
    "ir = IRsystem.from_corpus(corpus)\n",
    "\n",
    "# Save the IR system to a file\n",
    "with open('IRSystem/irsystem.pkl', 'wb') as output:\n",
    "    pickle.dump(ir, output, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Load the IR system from a file\n",
    "with open('IRSystem/irsystem.pkl', 'rb') as input:\n",
    "    ir = pickle.load(input)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
